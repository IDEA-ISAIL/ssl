{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# HeCo Tutorial\n",
    "#### This tutorial illustrates the use of HeCo algorithm [Self-supervised Heterogeneous Graph Neural Network with Co-contrastive Learning](https://arxiv.org/abs/2105.09111), an self-supervised cross-view contrastive learning method on heterogeneous graphs,  which enables the two views to collaboratively supervise each other and finally learn high-level node embeddings.\n",
    "#### The tutorial is organized as folows:\n",
    "#### 1. Preprocessing Data and Loading Configuration\n",
    "#### 2. Training the model\n",
    "#### 3. Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Preprocessing Data and Loading Configuration \n",
    "#### First, we load the configuration from yml file and the dataset. \n",
    "#### For easy usage, we conduct experiments to search for the best parameter across four datasets and find the proper value of parameters such that the performance of implemented HeCo is similar to the value reported in the original paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-21T19:54:09.272477400Z",
     "start_time": "2023-10-21T19:54:09.255915800Z"
    },
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "import os\n",
    "from src.methods import HeCo, Sc_encoder, Mp_encoder, HeCoDBLPTransform\n",
    "from src.trainer import SimpleTrainer\n",
    "from src.evaluation import LogisticRegression\n",
    "from src.datasets import DBLP, aminer, ACM, FreebaseMovies\n",
    "from src.evaluation import LogisticRegression\n",
    "from src.utils import create_data\n",
    "from src.config import load_yaml\n",
    "\n",
    "\n",
    "config = load_yaml('./configuration/heco_acm.yml')\n",
    "# config = load_yaml('./configuration/heco_dblp.yml')\n",
    "# config = load_yaml('./configuration/heco_freebase_movies.yml')\n",
    "# config = load_yaml('./configuration/heco_aminer.yml')\n",
    "device = config.device\n",
    "\n",
    "# -------------------- Data --------------------\n",
    "current_folder = os.path.abspath('')\n",
    "path = os.path.join(current_folder, config.dataset.root, config.dataset.name)\n",
    "if config.dataset.name == 'acm':\n",
    "    dataset = ACM(root=path)\n",
    "elif config.dataset.name == 'dblp':\n",
    "    dataset = DBLP(root=path, pre_transform=HeCoDBLPTransform())\n",
    "elif config.dataset.name == 'freebase_movies':\n",
    "    dataset = FreebaseMovies(root=path)\n",
    "elif config.dataset.name == 'aminer':\n",
    "    dataset = aminer(root=path)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "data_loader = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Training the Model\n",
    "#### In the second step, we first initialize the parameters of HeCo. There are two encoders for HeCo, specifically encoder for meta-path view and encoder for network schema view.  \n",
    "#### You may replace the any of the two encoders with the user-defined encoder. Please refer to the framework of the encoder in [heco.py](https://github.com/IDEA-ISAIL/ssl/edit/heco/src/methods/heco.py). Keep in mind that the encoders consist of class initialization and forward function. If you want to revise HeCo, make sure to include get_embs() function in your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-21T19:54:12.443915800Z",
     "start_time": "2023-10-21T19:54:12.438717600Z"
    },
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ------------------- Method -----------------\n",
    "encoder1 = Mp_encoder(P=config.dataset.P, hidden_dim=config.model.hidden_dim, attn_drop=config.model.attn_drop)\n",
    "encoder2 = Sc_encoder(hidden_dim=64, sample_rate=config.model.sample_rate, nei_num=config.dataset.nei_num, attn_drop=config.model.attn_drop)\n",
    "\n",
    "feats = data_loader.dataset._data['feats']\n",
    "feats_dim_list = [i.shape[1] for i in feats]\n",
    "method = HeCo(encoder1=encoder1, encoder2=encoder2, feats_dim_list = feats_dim_list, feat_drop=config.model.feat_drop, tau=config.model.tau)\n",
    "method.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### We train the model by calling the trainer.train() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-21T19:54:20.347461700Z",
     "start_time": "2023-10-21T19:54:15.059680200Z"
    },
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainer = SimpleTrainer(method=method, data_loader=data_loader, device=device, n_epochs=config.optim.max_epoch, lr=config.optim.lr, patience=config.optim.patience)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3. Evaluating the performance of HeCo\n",
    "#### In the last step, we evaluate the performance of HeCo. We first get the embedding by calling method.get_embs() function and then use logistic regression to evaluate its performance. \n",
    "#### The more choice of classifiers can be found in [classifier.py](https://github.com/IDEA-ISAIL/ssl/edit/molecure/src/evaluation/classifier.py), including SVM, RandomForest, etc. \n",
    "#### Besides, other evaluation methods in an unsupervised setting could be found in [cluster.py](https://github.com/IDEA-ISAIL/ssl/edit/molecure/src/evaluation/cluster.py) or [sim_search.py](https://github.com/IDEA-ISAIL/ssl/edit/molecure/src/evaluation/sim_search.py), including K-means method or similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-21T19:54:24.807636100Z",
     "start_time": "2023-10-21T19:54:23.650700200Z"
    },
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ------------------ Evaluator -------------------\n",
    "method.eval()\n",
    "data_pyg = dataset._data[config.dataset.target_type].to(method.device)\n",
    "embs = method.get_embs(data_loader.dataset._data['feats'], data_loader.dataset._data['mps']).detach()\n",
    "\n",
    "lg = LogisticRegression(lr=config.classifier.base_lr, weight_decay=config.classifier.weight_decay,\n",
    "                        max_iter=config.classifier.max_epoch, n_run=config.classifier.n_run, device=device)\n",
    "\n",
    "data_pyq = create_data.create_masks(data_pyg.cpu())\n",
    "lg(embs=embs, dataset=data_pyg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Optionally Save the Embedding Result -------------------\n",
    "import pickle as pkl\n",
    "f = open(os.path.join(current_folder, config.dataset.name + \"_embeddings.pkl\"),  \"wb\")\n",
    "pkl.dump(embs.cpu().data.numpy(), f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
