{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Sugrl Tutorial\n",
    "#### This tutorial illustrates the use of Sugrl algorithm [Simple Unsupervised Graph Representation Learning](https://ojs.aaai.org/index.php/AAAI/article/view/20748), a novel unsupervised graph representation learning method that employs a novel multiplet loss to leverage the complementary nature of structural and neighbor information, thereby enhancing inter-class variation. Additionally, it incorporates an upper bound loss to maintain a finite distance between positive and anchor embeddings, effectively reducing intra-class variation. This approach sidesteps the need for data augmentation and discriminators, enabling the production of efficient, low-dimensional embeddings.\n",
    "#### The tutorial is organized as folows:\n",
    "#### 1. [Preprocessing Data and Loading Configuration](InfoGraph.ipynb#L48)\n",
    "#### 2. [Training the model](InfoGraph.ipynb#L100)\n",
    "#### 3. [Evaluating the model](InfoGraph.ipynb#L206)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Preprocessing Data and Loading Configuration \n",
    "#### First, we load the configuration from yml file and the dataset. \n",
    "#### For easy usage, we conduct experiments to search for the best parameter across three datasets and find the proper value of parameters such that the performance of implemented InfoGraph is similar to the value reported in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from src.augment import RandomMask, RandomDropEdge, RandomDropNode, AugmentSubgraph, AugmentorList\n",
    "from src.methods import SugrlMLP, SugrlGCN\n",
    "from src.methods import SUGRL\n",
    "from src.trainer import SimpleTrainer\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from src.transforms import NormalizeFeatures, GCNNorm, Edge2Adj, Compose\n",
    "from src.datasets import Planetoid, Amazon, WikiCS,Coauthor\n",
    "from src.utils.create_data import create_masks\n",
    "from src.evaluation import LogisticRegression\n",
    "import yaml\n",
    "from src.utils.add_adj import add_adj_t\n",
    "from sklearn.impute import SimpleImputer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-21T19:54:09.272477400Z",
     "start_time": "2023-10-21T19:54:09.255915800Z"
    },
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load the configuration file\n",
    "# config = yaml.safe_load(open('./configuration/sugrl_wikics.yml', 'r', encoding='utf-8').read())\n",
    "config = yaml.safe_load(open(\"./configuration/sugrl_amazon.yml\", 'r', encoding='utf-8').read())\n",
    "# config = yaml.safe_load(open(\"./configuration/sugrl_coauthor.yml\", 'r', encoding='utf-8').read())\n",
    "# config = yaml.safe_load(open(\"./configuration/sugrl_cora.yml\", 'r', encoding='utf-8').read())\n",
    "print(config)\n",
    "data_name = config['dataset']\n",
    "torch.manual_seed(0)\n",
    "# np.random.seed(config.torch_seed)\n",
    "# device = torch.device(\"cuda:{}\".format(config.gpu_idx) if torch.cuda.is_available() and config.use_cuda else \"cpu\")\n",
    "\n",
    "# -------------------- Data --------------------\n",
    "pre_transforms = Compose([NormalizeFeatures(ord=1), Edge2Adj(norm=GCNNorm(add_self_loops=1))])\n",
    "data_name = config['dataset']\n",
    "\n",
    "current_folder = os.path.abspath('')\n",
    "# path = os.path.join(current_folder, config.dataset.root, config.dataset.name)\n",
    "\n",
    "if data_name==\"cora\":\n",
    "    dataset = Planetoid(root=\"pyg_data\", name=\"cora\", pre_transform=pre_transforms)\n",
    "if data_name==\"photo\": #92.9267\n",
    "    dataset = Amazon(root=\"pyg_data\", name=\"photo\", pre_transform=pre_transforms) \n",
    "elif data_name==\"coauthor\": # 92.0973\n",
    "    dataset = Coauthor(root=\"pyg_data\", name='cs', transform=pre_transforms)\n",
    "elif data_name==\"wikics\": #82.0109\n",
    "    dataset = WikiCS(root=\"pyg_data\", transform=T.NormalizeFeatures())\n",
    "    dataset = add_adj_t(dataset)\n",
    "    nan_mask = torch.isnan(dataset[0].x)\n",
    "    imputer = SimpleImputer()\n",
    "    dataset[0].x = torch.tensor(imputer.fit_transform(dataset[0].x))\n",
    "\n",
    "\n",
    "# dataset = Amazon(root=\"pyg_data\", name=\"photo\", pre_transform=pre_transforms)\n",
    "data_loader = DataLoader(dataset)\n",
    "data = dataset.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Training the Model\n",
    "#### In the second step, we first initialize the parameters of Sugrl. The backbones of the encoder are MLP and GCN. \n",
    "#### You may replace the encoder with the user-defined encoder. Keep in mind that the encoder consists of class initialization, forward function, and get_embs() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-21T19:54:12.443915800Z",
     "start_time": "2023-10-21T19:54:12.438717600Z"
    },
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ------------------- Method -----------------\n",
    "encoder_1 = SugrlMLP(in_channels=data.x.shape[1])\n",
    "encoder_2 = SugrlGCN(in_channels=data.x.shape[1])\n",
    "method = SUGRL(encoder=[encoder_1,encoder_2],data = data, config=config,device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### We train the model by calling the trainer.train() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-21T19:54:20.347461700Z",
     "start_time": "2023-10-21T19:54:15.059680200Z"
    },
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainer = SimpleTrainer(method=method, data_loader=data_loader, device=\"cuda:0\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3. Evaluating the performance of Sugrl\n",
    "#### In the last step, we evaluate the performance of Sugrl. We first get the embedding by calling method.get_embs() function and then use logistic regression to evaluate its performance. \n",
    "#### The more choice of classifiers can be found in [classifier.py](https://github.com/IDEA-ISAIL/ssl/edit/molecure/src/evaluation/classifier.py), including SVM, RandomForest, etc. \n",
    "#### Besides, other evaluation methods in an unsupervised setting could be found in [cluster.py](https://github.com/IDEA-ISAIL/ssl/edit/molecure/src/evaluation/cluster.py) or [sim_search.py](https://github.com/IDEA-ISAIL/ssl/edit/molecure/src/evaluation/sim_search.py), including K-means method or similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Evaluator -------------------\n",
    "data_pyg = dataset.data.to(method.device)\n",
    "embs = method.get_embs(data_pyg.x, data_pyg.adj_t).detach()\n",
    "lg = LogisticRegression(lr=0.001, weight_decay=0, max_iter=3000, n_run=50, device=\"cuda\")\n",
    "create_masks(data=data_pyg.cpu())\n",
    "lg(embs=embs, dataset=data_pyg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
